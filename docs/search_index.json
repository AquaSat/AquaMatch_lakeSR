[["introduction.html", "lakeSR: Compiled Satellite Surface Reflectance and Surface Temperature for Lakes in the United States and US Territories 1 Introduction 1.1 Code Architecture 1.2 Running the code within this repository", " lakeSR: Compiled Satellite Surface Reflectance and Surface Temperature for Lakes in the United States and US Territories ROSSyndicate 2023-10-26 1 Introduction This bookdown document (Xie 2016) explains the methodology we use in the acquisition and compilation of satellite surface reflectance and surface temperature data for all lakes in the United States and US Territories. This product, “lakeSR”, is a component of the AquaSat (v2) suite, an effort to create a database of lake and river water quality observations alongside remote sensing data. Currently, lakeSR is comprised of the historical Landsat record from 1984 until mid-2023, comprised of data from the following missions: Landsat 4 Thematic Mapper (TM) Landsat 5 TM Landsat 7 Enhanced Thematic Mapper Plus (ETM+) Landsat 8 Operational Land Imager/Thermal Infrared Sensor (OLI/TIRS) Landsat 9 OLI/TIRS Together the Landsat archive of lakeSR is referred to as “lakeSR-LS_C2_SRST” (Landsat Collection 2 Surface Reflectance and Surface Temperature). There will be additional satellite data incorporated into the lakeSR product in the future. lakeSR acquires tabular data summaries of satellite-derived surface reflectance and surface temperature data at central locations within a lake and at locations identified with monitoring records from the Water Quality Portal from the AquaMatch component of AquaSat. 1.1 Code Architecture lakeSR is built on the {targets} workflow management system for R (Landau 2021). The {targets} architecture is based on lists of functions performed in a specific order, each function called a target. The primary benefit of {targets} workflows is that code is only run if a target, a target’s code, or a target’s dependencies have changed (or become “outdated” in {targets} speak). lakeSR is broken down into functional groups of targets, listed below with a brief summary about what task(s) each group completes. a_Calculate_Centers: This {targets} list calculates “Pole of Inaccessibility” (POI) for all lakes, ponds, reservoirs, and playas greater than 1 hectare in surface area using the NHDPlusHR polygons using the {nhdplusTools} package and the poi() function in the {polylabelr} package. For all waterbodies in Alaska, POI were calculated based on the NHD Best Resolution file for the entire state because the NHDPlusHR is not complete for AK. Note: this group of targets will take up to 4h to complete. See Section 2 for additional background and detailed methodology. b_pull_Landsat_SRST_poi: This {targets} group uses the config file config_files/config_poi.yml and the “Pole of Inaccessibility” points created in the a_Calculate_Centers group to pull Landsat Collection 2 Surface Reflectance and Surface Temperature using the GEE API. In this group, we use the most strict LS4-7 pixel filters which include the sr_cloud_mask filter. This filter is a conservative filter, removing artefacts from upstream products that are used to create the SR product. This group of targets ends with a branched target that maps over each of the WRS2 path rows that intersect with the points. Note: this group of targets takes a very, very long time, averaging about 1 hour per path-row branch. There are just under 800 path rows executed in this branch. See Section 5 for additional background and detailed methodology. 1.2 Running the code within this repository If you have followed all of the set up instructions, including those outlined in Section 3, the code within this repository can be triggered by running the run_targets.Rmd file with the rProj file lakeSR open in your RStudio console. If you do not wish to re-run the entirety of the {targets} workflow, we encourage you to download the lakeSR_targets.zip file [[NOTE: will need to zip this later and/or add to the data release]], rename it _targets and copy it into the root directory of this repository, overwriting the existing _targets folder and contents. Citations "],["locs-data-acq.html", "2 Locations of Data Acquisition 2.1 Pole of Inaccessibility 2.2 Lakes included in lakeSR 2.3 Implementation", " 2 Locations of Data Acquisition As noted in the Introduction (Section 1), for the purposes of AquaSat, surface reflectance and surface temperature data are acquired at specific, centrally-located points within waterbodies (typically in pelagic locations of lakes) and at locations where there are in situ data. The data acquired at locations where there are in situ data are acquired to create location-specific algorithms using the AquaMatch database, which can then be applied to the data collected over the centrally-located point across all waterbodies in the lakeSR database. lakeSR does not acquire nor summarize data over the entire waterbody’s surface, as it is computationally impractical for most large lakes that cross multiple satellite path-rows or tiles. We are planning to investigate the variability differences in acquiring data over varying buffer distances to support this decision (GitHub Issue #14). At this time, the buffer used is a 120m radius of any given data acquisition location. 2.1 Pole of Inaccessibility The concept of “pole of inaccessibility” (POI) (Stefansson 1920) is used to define the geographic center of a circle with the largest circumference within any complex polygon. The foundational principle is used widely to describe the arctic pole of inaccessiblity, that is the point in the northern arctic circle that is the furthest from land, but has also been used to describe the geographic center of landmasses (Garcia-Castellanos and Lombardo 2007). For lakeSR, we use POI to determine the point in a lake that is furthest from the shoreline using the polylabelr::poi() function (Larsson 2020), which calculates a point in space and the radius of the circle used to define the POI. 2.2 Lakes included in lakeSR For lakeSR, we use the NHDPlusHR dataset for lakes within the conterminous US and US Territories using the nhdplusTools::download_nhdplushr() function (Blodgett and Johnson 2023). All HUC4s were downloaded and processed on 2023-10-05 using the most updated version available at the time of download. Because the NHDPlusHR dataset is incomplete for Alaska (Figure 2.1), we used the NHD Best Resolution File for the state of AK (US Geological Survey, n.d.). Figure 2.1: NHDPlusHR dataset availability, courtesy of the USGS. For every HUC4 included in the NHDPlusHR dataset and the state of Alaska NHD Best Resolution dataset, all waterbodies are limited to those with FCodes belonging to the following groups: 390 (lake/pond), 436 (reservoir), and 361 (playa) and are at least 0.01 km2 (1 hectare) in area according to the area value provided in the NHD file. This filtering resulted in 1,135,312 waterbodies included in our dataset, including 415,008 from Alaska. For each waterbody, the POI and distance-to-shore radius was calculated using the polylabelr::poi() function. In order to accurately calculate distance-to-shore, each waterbody was converted to the proper Universal Transverse Mercator (UTM) projection calculated from the mean longitudinal value of the polygon vertices prior to applying the poi() function. By using the point-local UTM projection, we decrease distortion expected from any single CRS used to represent all of the locations from which we have lakes. The latitude and longitude values of the POI were transformed to decimal degrees in World Geodetic System 1984 (WGS84) (EPSG:4326) from UTM easting and northing coordinates for use later in the workflow. It is important to note that the poi() function does not perform particularly well on larger polygons, however the points calculated should be an acceptable proxy for pelagic lake conditions. [[Will add additional detail from analysis of buffer sizes.]] 2.3 Implementation The code for gathering NHD waterbodies and calculating their respective POIs is found in {targets} group a_Calculate_Centers which is located in the script a_Calculate_Centers.R. The network graph (Figure 2.2) for this group depicts the dependencies between each of the targets in this group. ## - \\ | / - \\ | / - \\ | / Figure 2.2: Network graph of the targets in the a_Calculate_Centers {targets} group. On a high level, the processing begins by acquiring the polygons of all US states and territories using the {tigris} package (Walker 2023) (US_state_territories). These polygons are used to acquire a list HUC4s that intersect with each municipal boundary using the nhdplusTools::get_huc() function (HUC4_dataframe), which are then reduced to distinct HUC4’s and transformed into a vector of HUC4s (HUC4_list). As an error-handling measure, empty_hucs_file is created (not pictured in Figure 2.2) to collect a list of HUC4s that do not have high resolution files available for download (Figure 2.1). The target all_poi_points is created by calculating POIs for all waterbodies &gt; 1 hectare and having an FCode of 390, 436, or 361 from each HUC4 in the HUC4_list. For this target, we use the dynamic branching feature to iterate over each item in the HUC4_list. See the script calculate_centers_HUC4.R for details on the function applied in this target. The output of the all_poi_points target include multiple .csv files - these files are collated in the target all_poi_points, which outputs a .feather file (tracked as NHDHR_poi_points) containing all the POIs resulting from the NHDPlusHR polygon files. The NHDPlusHR contains a small number of sub-HUC4 waterbodies (specifically a few HUC8’s and HUC10’s) in the state of AK, but to make processing more straightforward, POIs from polygons from the NHDPlusHR that were from these files were removed (NHD_poi_points_noAK). The target make_AK_poi_points downloads the NHD Best Resolution geopackage and calculates POIs for each waterbody polygon of the same size and type as stated previously. (See the script calculate_AK_poi.R) The resulting file (tracked as AK_poi_points), is combined with the NHD_poi_points_noAK target to create a harmonized and collated file in the target combined_poi_file (see collate_NHDHR_AK.R, the output file is tracked as combined_poi_points). Citations "],["software-settings.html", "3 Satellite Data Acquisition Software and Settings 3.1 {reticulate} Conda Environment 3.2 Google Earth Engine Setup", " 3 Satellite Data Acquisition Software and Settings Currently, all satellite data in AquaSat are obtained using the Python API for Google Earth Engine (GEE) (Gorelick et al. 2017). While the orchestration of data acquisition is performed by {targets}, a workflow management program for R, all code directly related to GEE data acquisition is written in Python. 3.1 {reticulate} Conda Environment RStudio (Posit team 2023) is an IDE that, alongside the {reticulate} package (Ushey, Allaire, and Tang 2023), facilitates integration of R and Python code within the same environment. In lakeSR, we use a singular R script to set up a {reticulate} Conda environment that is invoked at the beginning of a {targets} run (lines 8-12 of the _targets.R file) to be sure that our Python code runs consistently. Python and python modules and versions used in **lakeSR**. Software/Py Module version citation Python 3.8.18 Python Software Foundation, www.python.org earthengine-api 0.1.374 (Gorelick 2023) pandas 2.0.3 (The pandas development team 2023) fiona 1.9.5 (Gillies 2023) pyreadr 0.5.0 (Fajardo 2023) pyarrow 13.0.0 (Apache Arrow Developers 2023) 3.2 Google Earth Engine Setup 3.2.1 Create a GEE account Creation of a GEE is easy and free. Click ‘Get Started’ at the far right side of the earthengine.google.com webpage to create an account: 3.2.2 gcloud CLI This workflow requires the installation and initiation of gcloud CLI, a command-line tool set for accessing Google Cloud Resources. All settings for lakeSR are default gcloud configurations using a singular GEE project. 3.2.3 GEE Authentication Once gcloud is installed and initialized and the Conda environment is set up, you can authenticate your GEE instance. For this workflow, this is completed in the terminal and manually authenticating within the browser. See the run_targets.Rmd file for directions to complete this task. 3.2.4 GEE project setting lakeSR is run in a specific GEE project associated with our authenticated account. If you wish to re-run this code as written, you will not have proper access because the code refers to our specific GEE project (each of the yaml files in the config_files folder point to this within the ee_proj setting. You will need to update this with your desired GEE project. If you are new to GEE, go to code.earthengine.google.com and enter the project name listed in the top right hand corner of your screen: Alternatively, you can create an GEE project for this task in the dropdown menu accessed by clicking on the icon to the right of the highlighted box in the figure above. Citations "],["landsat-collection-2-surface-reflectance-and-surface-temperature.html", "4 Landsat Collection 2 Surface Reflectance and Surface Temperature 4.1 Background Information 4.2 Surface Reflectance Product 4.3 Surface Temperature", " 4 Landsat Collection 2 Surface Reflectance and Surface Temperature 4.1 Background Information The information presented in this section originates from the NASA Landsat Science website and has been summarized here for the purpose of providing background information about the Landsat archive relevant to the creation and use of lakeSR. The Landsat archive of multispectral and thermal data in lakeSR is composed of Landsat missions 4 through 9 and spans more than 40 years. Mission Launch Date End of Science Mission Decommission Date Landsat 4 TM 1982-07-16 1993-12-14 2001-06-15 Landsat 5 TM 1984-03-01 2011-11-18 2013-06-05 Landsat 7 E TM+ 1999-04-15 2022-04-06 N/A Landsat 8 OLI/T IRS 2013-02-11 N/A N/A Landsat 9 OLI-2/TIR S-2 2021-09-27 N/A N/A The image record for Landsat 4 is not consistent nor robust due to a data transmitter failure early in service. Landsat 6 did not achieve orbit. 4.1.1 Spectral Response While the nominal bands for each of the missions within the archive is relatively consistent (with the addition of an Aerosol band beginning Landsat 8), the precise spectral response for each nominal band shifted beginning with Landsat 8 OLI/TIRS: S ensors Ae rosol Blue Green Red Near Inf rared (NIR) Short Wave Inf rared 1 (SWIR 1) Short Wave Inf rared 2 (SWIR 2) Th ermal TM ETM+ N/A 0.45 -0.52 μm 0.52 -0.60 μm 0.63 -0.69 μm 0.77 -0.90 μm 1.55 -1.75 μm 2.08 -2.35 μm 1 0.40- 12.50 μm OL I/TIRS OLI-2/ TIRS-2 0 .435- 0.451 μm 0 .452- 0.512 μm 0 .533- 0.590 μm 0 .636- 0.673 μm 0 .851- 0.879 μm 1 .566- 1.651 μm 2 .107- 2.294 μm 10 .60-1 1.19, 1 1.50- 12.51 μm 4.1.2 Sensor Resolution The spatial resolution of the Level 1 data has not changed for optical bands (Aerosol, RGB, NIR, SWIR) but has varied over the history for thermal data: Sensors Optical Bands Thermal Bands TM 30 120 ETM+ 30 60 OLI/TIRS OLI-2/TIRS-2 30 100 All Collection 2 Level 2 Surface Reflectance and Surface Temperature data have been resampled to 30m. Alongside the pixel resolution of the sensors is the radiometric resolution at which the data are stored. TM and ETM+ data are stored as 8-bit data products, OLI data are quantitized to 12 bits and Landsat 9 to 14 bits. This equates to 256 shades per band for Landsat 4-7, 4,096 shades for Landsat 8 and 16,384 shades for Landsat 9, where higher numbers allow for greater precision of measurement in a given band. All Collection 2 Level 2 Surface Reflectance and Surface Temperature data have been rescaled to 16 bits. 4.2 Surface Reflectance Product The information presented in this section originates from the USGS Landsat Collection 2 Surface Reflectance product page and has been summarized here for the purpose of providing background information about the Landsat archive relevant to the creation and use of lakeSR. The Landsat Collection 2 Surface Reflectance (SR) product is a Level 2 data product that has been atmospherically corrected from the Level 1 Top of Atmosphere product using a myriad of inputs to create a reasonably consistent data product across space and time. The USGS EROS describes the SR product as follows: Surface reflectance improves comparison between multiple images over the same region by accounting for atmospheric effects such as aerosol scattering and thin clouds, which can help in the detection and characterization of Earth surface change. Surface reflectance is generated from Level-1 inputs that meet the &lt;76 degrees Solar Zenith Angle constraint and include the required auxiliary data inputs to generate a scientifically viable product. 4.2.1 SR Atmospheric Processing The SR product for Landsat 4-7 is calculated using the Land Ecosystem Distrubance Adaptive Procesing System (LEDAPS) (Schmidt et al. 2013) and Landsat 8 and 9 SR data are calculated using the Land Surface Reflectance Code (LaSRC) algorithm (Vermote et al. 2018). The two algorithms are functionally different, but the outcome is the same: a consistently-processed surface reflectance product that is available worldwide. See the table under section heading ‘Differences in Surface Reflectance Processing Algorithms’ on the USGS Landsat C2 website for details. 4.3 Surface Temperature The information presented in this section originates from the USGS Landsat Collection 2 Surface Temperature product page and has been summarized here for the purpose of providing background information about the Landsat archive relevant to the creation and use of lakeSR. The Landsat Collection 2 Surface Temperature (ST) product is calculated using a single-channel algorithm (M. J. Cook 2014; M. Cook et al. 2014) to convert the thermal band data to temperature estimates in degrees Kelvin. These data are considered interoperable over space and time with few differences in the ST algorithm product within Collection 2, with the acknowledgement of the previously-documented spectral and radiometric resolution differences. Citations "],["LS-C2-SRST.html", "5 lakeSR-LS_C2_SRST Data Product 5.1 Overview 5.2 Data Acquisition Script 5.3 ", " 5 lakeSR-LS_C2_SRST Data Product The lakeSR-LS_C2_SRST data product is a set of tabular datasets, representing either the SR and ST data summarized for the POI location which is meant to represent pelagic conditions at a given waterbody (identified by its NHD Permanent Identifier, see Section 2) or representing the SR and ST data summarized for any sampling location(s) within a waterbody detected in the WQP in the early stages of AquaMatch. Both types of data contain “full stacks” of the Landsat Collection 2 record - that is, all summarized Landsat data available from all Landsat missions. 5.1 Overview At a high level, the workflow for data acquisition is as follows: read in and format the yaml configuration file for the GEE run for POI: completed in config_file_poi, yml_file_poi, yml_poi reformat the locations file for the GEE run for POI: completed in ref_locs_poi_file, ref_locations_poi determine the WRS-2 path rows (or ‘tiles’) that intersect with the locations file for POI: completed in WRS_tiles_poi add the WRS-2 path rows to the reformatted locations file for quicker processing for POI: completed in poi_locs_WRS_file, poi_locs_WRS, poi_locs_WRS_latlon iteratively run the GEE script per WRS-2 tile for POI: completed in eeRun_poi check to see that all tasks are complete in GEE before moving to next step for POI: completed in poi_tasks_complete ## - \\ | / - \\ | / - \\ | / - \\ | Figure 5.1: Network graph of the targets in the b_pull_Landsat_SRST_poi {targets} group. Not pictured in graph: config_file_poi, yml_file_poi, poi_locs_WRS_latlon. 5.2 Data Acquisition Script The data acquisition pipeline for POIs and sampling locations for the lakeSR-LS_C2_SRST data product is the same, but the pipeline is initialized with two different yaml configuration files. This section will walk through the code in b_pull_Landsat_SRST_poi/py/runGEEperTile.py and the functions called in that code which are stored in b_pull_Landsat_SRST_poi/py/GEE_functions.py. 5.3 "],["citations.html", "6 Citations", " 6 Citations "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
