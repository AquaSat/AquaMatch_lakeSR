---
title: "Run Targets - AquaMatch_lakeSR pipeline"
---

# Purpose

This script loads all necessary packages to run the {targets} pipeline for 
AquaMatch_lakeSR then runs it! lakeSR extracts summaries of the Landsat Collection
2 Surface Reflectance Product for the furthest point from shore (polygon edge) for
all lakes/reservoirs/ponds/impoundments in the United States and Territories greater
than 1ha and all waterbodies deemed "intermittent" by the NHD greater than 4ha. 

This R Markdown document is not meant to be "knit", rather to walk the user through
the process of setting up and running this workflow. Additional overview about
the {targest} workflow is available in the README file.


## Prerequsites

In order to use this workflow, you must have a [Google Earth Engine account](https://earthengine.google.com/signup/) 
and have configured a [Google Cloud Project](https://developers.google.com/earth-engine/cloud/projects) 
and you will need to[download, install, and initialize gcloud](https://cloud.google.com/sdk/docs/install). 


## Completing the config.yml file

Configuration of the config.yml file is necessary for this workflow to function.
You will need to modify the yaml file in order for this workflow to work if you
are running this and do not have access to the ROSSyndicate Google Account. 
See the comments within the config.yml file for guidance on parameter definitions 
and how to format each parameter. The workflow is set up to use the config file
in the folder path `b_pull_Landsat_SRST_poi/config_files/config_poi.yml`, but we
also provide a blank config file with default settings at the path 
`b_pull_Landsat_SRST_poi/config_files/config.yml` - in order for {targets} to use
an updated config file, you will need to change the file path on line 18 of the 
`_targets.R` script. The only parameters that need to be filled in are those in 
the section `google_settings`.


## Confirm GEE access via API

First, create a virtual environment for this use of Python. In order for this
chunk of code to run properly, you will need to make sure that you are in a fresh
R session.  

```{r}
source("python/pySetup.R")
```

The final output of the previous cell will be "conda environment activated" in your
console if the setup was successful. 

Now, we'll make sure that the Earth Engine API is set up correctly. Running this
code chunk will open a web browser. Make sure that the credentials you use are
the same that appear in your config file. When your browser will indicate that you 
have successfully authenticated, return here to finish this step.

```{python}
import ee
import yaml

# note, you will need to update this file path if you are using a different config
# file
with open("b_pull_Landsat_SRST_poi/config_files/config_poi.yml") as config:
    try:
        cfg = yaml.safe_load(config)
    except yaml.YAMLError as exc:
        print(exc)

google = cfg["google_settings"]
ee_proj = next(item['ee_proj'] for item in google if 'ee_proj' in item)

ee.Authenticate(auth_mode="localhost")
ee.Initialize(project=ee_proj)

```

Executing ee.Initialize() should result in no error or warning messagaes.


## Install necessary packages

Define package installer function

```{r package_installer}
package_installer <- function(x) {
  if (x %in% installed.packages()) {
    print(paste0("{", x ,"} package is already installed."))
    } else {
      install.packages(x)
      print(paste0("{", x ,"} package has been installed."))
    }
  }
```

List packages that need to be checked for install which are used in this workflow, 
and walk the function along them all.

```{r walk_package_installer}
packages <- c("bookdown",
              "nhdplusTools",
              "polylabelr",
              "reticulate",
              "rmapshaper",
              "sf",
              "tarchetypes",
              "targets",
              "tidyverse",
              "tigris",
              "yaml")
lapply(packages, package_installer)
# this workflow requires the most up-to-date version of {nhdplusTools}
update.packages("nhdplusTools")
```

You are now ready to run the pipeline!

## Run the targets pipeline and output a network graph.


Just as a heads up, running this workflow will take multiple hours.

```{r run_targets}
library(targets)

# run the pipeline
tar_make()
```


### Create a network diagram of the workflow.

```{r see_targets_net}
tar_visnetwork()
```

